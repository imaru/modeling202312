---
title: '202312'
author: "Toshihide Imaruoka"
date: "2023-12-19"
output:
  rmdformats::downcute:
    highlight: kate
    css: mycss.css
    dev: "ragg_png"
---
# 3-7: 正規線形モデル
## 2. モデルの構造
  * 正規線形モデル：リンク関数が恒等関数であるモデルの総称
  * ここで使うモデル
    * $売り上げの平均値=晴れ＋雨＋気温$
    * $\mu_i=\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+\beta_3x_{i3}$
    * $y_i\sim Normal(\mu_i, \sigma^2)$

## 3. 分析の準備
  * いつもの
```{r}
library(rstan)
library(brms)
rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
```
  
## 4. データの読み込み
  * 天気と気温が売り上げの平均値に影響するというモデルのためのデータ
```{r}
library(ggplot2)
data37<-read.csv('3-7-1-beer-sales-4.csv')
summary(data37)

ggplot(data=data37,
       mapping=aes(x=temperature, y=sales))+
      geom_point(aes(color=weather))+labs(title="effect of temperature and weather on beer sales")
```

## 5. brmsによる正規線形モデルの推定
```{r}
brms37<-brm(
  formula = sales ~ weather + temperature,
  family = gaussian(),
  data = data37,
  seed = 1,
  prior = c(set_prior("", class="Intercept"),
            set_prior("", class="sigma"))
)
brms37
eff<-conditional_effects(brms37, effect="temperature:weather")
plot(eff, points=TRUE)
eff_pre<-conditional_effects(brms37, effect="temperature:weather", method="predict")
plot(eff_pre, points=TRUE)
```

  * weathersunnyの推定値が29.45（信用区間は0をまたがない）: 晴れの日には＋29万円の効果
  * temperatureの推定値が2.55（信用区間は0をまたがない）：気温1℃で2.55万円増加
 
## 6. 補足：正規線形モデルのデザイン行列（Stanによる解析）
  * まずはbrmsによる解析からstanファイルを生成してみる
  
```{r}
stancode(brms37)
```
  
  * 続いて3部4章のStanファイル
  
```{stan output.var='stan37'}
data{
  int N;
  int K; //デザイン行列列数
  vector[N] Y; //売り上げを代入するベクトル
  matrix[N, K] X; //デザイン行列
}
parameters{
  vector[K] b;
  real<lower=0> sigma;
}
model{
  vector[N] mu = X * b;
  Y ~ normal(mu, sigma);
}
```

  * Stanコードを実行
  
```{r stan37}
# デザイン行列
formula37<-formula(sales ~ weather + temperature)
mtx37<-model.matrix(formula37, data37) ## data37はcsvファイルを読み込んだデータ

standata37<-list(
  N=nrow(data37),
  K=4, # 切片、天気雨、天気晴れ、気温
  Y=data37$sales,
  X=mtx37
)

library(rstan)
stanres37<-rstan::sampling(stan37,
                           data=standata37,
                           seed=1)
stanres37

```
  * brmsとほぼ同じ結果になった

# 3-8: ポアソン回帰モデル
## 2. モデルの構造
  * ポアソン分布：離散型で0以上の整数データのとき
    * パラメータ$\lambda$
    * 期待値も分散も$\lambda$
    * リンク関数は$log$
  * ここでの例
    * 釣り
    * 釣果＝天気＋気温
      * ただしポアソン分布を考えるので
      * $log(\lambda) = \beta_0 + \beta_1x_1 + \beta_2x_2$
        * $個人的には\lambda_i = exp(\beta_0 + \beta_1x_1 + \beta_2x_2)$の方が理解しやすい（と、3-1でも書いた。緑本にはこう書いてある。）
      * $y_i \sim Poiss(\lambda_i)$
      * 馬場本では$log(\lambda)=$の式もあって、下の式もあるのが分かりにくい感じがする
        * $\lambda = \beta_0 + \beta_1x_1 + \beta_2x_2$
        * $y_i \sim Poiss(exp(\lambda_i))$

## 3. 分析の準備
  * いつもの
```{r}
library(rstan)
library(brms)
rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
```
  
## 4. データの読み込みと可視化
```{r}
data38<-read.csv("3-8-1-fish-num-1.csv")
summary(data38)
ggplot(data=data38,
       mapping=aes(x=temperature, y=fish_num))+
  geom_point(aes(color=weather))+
  labs(title="effect of temperature and weather on num of fishes")
```

## 5. brmsによるポアソン回帰モデルの推定
  * 正規線形モデルとほぼ同じだけど、~~sigmaの事前分布の指定がない（推定しないから）~~
    * と、いうよりポアソン回帰には$\sigma$なんてパラメータはないから、の方が正しい?
  
```{r}
brms38<-brm(
  formula = fish_num ~ weather + temperature,
  family=poisson(),
  data=data38,
  seed=1,
  prior=c(set_prior("",class="Intercept"))
)
brms38
```

## 6. 推定されたモデルの解釈
  * weathersunnyの係数の推定値は-0.60
    * ただし、exp(-0.60)=0.5488
    * 晴れると0.54倍になる
      * 倍でいいの？と思ったけど、expの中の足し算は掛け算。
  * temperatureは0.08
    * exp(0.08)=1.0832
    * 晴れると微妙に増える
  * 釣果数の期待値$\lambda=exp(-.78-0.60 \times 晴れかどうか+0.08 \times 気温)$
  
## 7. 回帰曲線の図示
  * 95%ベイズ信用区間つき
```{r}
eff38<-conditional_effects(brms38,
                          effects="temperature:weather") # weatherを前にすれば横軸がweatherになる
plot(eff38, points=TRUE)
```

  * 予測区間
    * 過分散となることがある
      * 期待値と分散が一つのパラメータで決まるから、とあるけど、なぜ？
      * 緑本で「過分散」を調べてみる
        * P149脚注: 「現実のカウントデータでは平均よりも分散の方が大きくなる場合がほとんどです。詳しくは7.6節（以下略）」
        * P165 7.6節: ここでは過分散の原因として個体差を挙げている。種子数の例を使っていて、本来正規分布する植物の大きさが観測されていないため、という理屈。緑本的にはここから一般化線形混合モデル（GLMM）を使うという流れ。
        * 馬場本でも第4分階層ベイズ（一般化線形混合モデル）と進む
```{r}
set.seed(1)
eff_pre38<-conditional_effects(brms38,
                              method='predict',
                              effects='temperature:weather',
                              probs=c(0.05, 0.995))
plot(eff_pre38, points=TRUE)
```


## 8. 補足：ポアソン回帰モデルのためのStanファイルの実装
  * ここでもStanファイルから実行してみる
  
```{stan output.var='stan38'}
data{
  int N;
  int fish_num[N];
  vector[N] temp;
  vector[N] sunny;
}
parameters{
  real Intercept;
  real b_temp;
  real b_sunny;
}
model{
  vector[N] lambda=exp(Intercept + b_sunny*sunny + b_temp*temp);
  fish_num~poisson(lambda);
}
```

  * 上のStanファイルを実行
    * 下の計算ではデータからダミー変数を作ったけど、それをやる必要はない？
  
```{r stan38}
data38<-read.csv('3-8-1-fish-num-1.csv') #データ読み込み
data38$sunny<-as.integer(data38$weather=='sunny') # 晴れの日ダミー変数作成
standata38<-list(  # Stanに渡すためにリストにまとめる
  N=nrow(data38),
  fish_num=data38$fish_num,
  temp=data38$temp,
  sunny=data38$sunny
)

res38<-rstan::sampling(stan38, data=standata38, seed=1)
print(res38)
```
  * デザイン行列バージョンも一応。

```{stan output.var='modelmtx38'}
data{
  int N;
  int K;
  int Y[N];
  matrix[N, K] X;
}
parameters{
  vector[K] b;
}
model{
  vector[N] lambda = X * b;
  Y ~ poisson_log(lambda);
}
```

  * この下で使ってるformula関数、model.matrix関数が結構謎。model.matrixは名義尺度のweatherからダミー変数weathersunnyを自動的に生成しているように見える。
    * 多分それをやってくれる関数

```{r modelmtx38}
data38<-read.csv('3-8-1-fish-num-1.csv') #データ読み込み
formula38<-formula(fish_num~weather+temperature)
mtx38<-model.matrix(formula38, data38)
standatamtx38<-list(
  N=nrow(data38),
  K=3,
  Y=data38$fish_num,
  X=mtx38
)
resmtx38<-rstan::sampling(modelmtx38, data=standatamtx38, seed=1)
print(resmtx38)
```

# 3-9. ロジスティック回帰モデル
## 2. モデルの構造
  * 2値データ
  * 種子が発芽するかしないか
    * 発芽率$p$
    * 確率分布：二項分布
    * リンク関数：ロジット関数
    * $p_i$: 発芽確率
    * $y_i$: 10粒中の発芽数
    * $x_{i1}$: 日当たり有無のダミー変数
    * $x_{i2}$: 栄養素量
    * $p_i = logostic(\beta_0+\beta_1x_{i1}+\beta_2{xi})$ :パラメータ$p$は0から1の間で変化するロジスティック関数に従う
    * $y_i\sim Binom(10, p_i)$
    
## 3. 分析の準備
```{r}
library(rstan)
library(brms)
rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
```

## 4. データの読み込みと可視化
```{r}
dat39<-read.csv('3-9-1-germination.csv')
summary(dat39)
ggplot(data=dat39, 
       mapping=aes(x=nutrition, y=germination, color=solar)) + geom_point() + labs(title='relation between germination and solar and nutrition')
```

## 5. brmsによるロジスティック回帰モデルの推定
```{r}
brms39<-brm(
  germination | trials(size) ~ solar + nutrition,
  family = binomial(),
  data=dat39,
  seed=1,
  prior=c(set_prior("", class="Intercept"))
)
print(brms39)
```

  * 結果
    * solarsunshineの効果あり
    * nutritionの効果あり
  * ただし、係数の解釈に注意が必要（リンク関数がロジット関数だから）
  * オッズ比：$オッズ=\frac{p}{1-p}$
  * ロジスティック回帰モデルの係数＝対数オッズ比
    * 係数にexp()をかけるとオッズ比になる
  * 例を使ってオッズ比の説明
    *日光と栄養素が発芽に与える影響。データ3つ。
    * やってみる
    
```{r}
egdata<-data.frame(
  solar=c('shade','sunshine','sunshine'),
  nutrition=c(2,2,3),
  size=c(10,10,10)
)
egdata
linear_fit<-fitted(brms39, egdata, scale='linear')[,1] # 最後の[,1]は1列目のみという意味
fit<-1/(1+exp(-linear_fit))
fit
```

  * ここまでやったこと
    * データ（日照の有無、栄養素の量、個数を指定）
    * fitted関数を使って、データに対してさっき推定したモデルを適用、線形予測子の予測値を知る（linear_fitted）。
      * fitted関数についてはちょっと調べてみたけど、詳細は不明。'linear'ではなく'response'を指定するとロジスティック関数に入れた値に近い値が出てくるけど、ちょっと違う。
    * 線形予測子が出す値をロジスティック関数に与えることで、各データに対する発芽率が得られる（fit）。
    
```{r}
odds_1 <- fit[1]/(1-fit[1])
odds_2 <- fit[2]/(1-fit[2])
odds_3 <- fit[3]/(1-fit[3])
```

  * この後、オッズ比を算出する
    * odds_2/odds_1: 1と2の違いは日照の有無なので、日照によって成功率がどう変わるかが分かることになる
    * で、この値が日照の係数のexpと同じと言っている
    
```{r}
odds_2/odds_1

coef<-fixef(brms39)[,1] 
exp(coef["solarsunshine"])
```

  * 確かに同じになる

## 7. 回帰曲線の図示
  * 図示。これまで同様。ただし、引数conditionsが必要（本のサポートページに記述あり）。
  
```{r}
eff<-conditional_effects(brms39, effects='nutrition:solar', conditions=data.frame(size=10))
plot(eff, points=TRUE)
```
  
  * せっかくなので予測区間も書いてみる
  
```{r}
eff_pre<-conditional_effects(brms39, effects='nutrition:solar', conditions=data.frame(size=10), method='predict')
plot(eff_pre, points=TRUE)
```

  * ポアソン回帰同様、こちらもギザギザに。二項分布に従う乱数は整数だからという解釈でOK？
  * ところで、「○○回帰モデル」命名の謎
    * ポアソン分布に従うデータのモデル推定を、リンク関数を対数関数で実施する（線形予測子をexpで処理）→これをポアソン回帰と呼ぶ
    * 二項分布に従うデータのモデル推定を、リンク関数をロジット関数で実施する（線形予測子をlogisticで処理）→これをロジスティック回帰と呼ぶ
    * なんで？
    
## 8. 補足: ロジスティック回帰のためのStanファイルの実装
  * Stanでもやってみる。デザイン行列で。
```{stan output.var='stanmodel39'}
data{
  int N;
  int K;
  int Y[N];
  int binom_size[N];
  matrix[N, K] X;
}
parameters{
  vector[K] b;
}
model{
  vector[N] prob = X * b;
  Y ~ binomial_logit(binom_size, prob); #binomial_logitには引数2つ必要
}
```

```{r stanmodel39}
dat39<-read.csv('3-9-1-germination.csv')
formula39<-formula(germination|size~solar+nutrition)
mtx39<-model.matrix(formula39, dat39)
standatamtx39<-list(
  N=nrow(dat39),
  K=3,
  binom_size=dat39$size,
  Y=dat39$germination,
  X=mtx39
)
resmtx39<-rstan::sampling(stanmodel39, data=standatamtx39, seed=1)
print(resmtx39)

```

## 9. 補足: 試行回数が常に1の場合
  * そういうときは二項分布ではなくベルヌーイ分布を使おうね、という話
  
# 練習
  * 一昨年の基礎実験2の視覚探索実験の結果
    * 2要因（セットサイズ、難易度）
    * 従属変数：反応時間（秒）
    * データ：vsres.csv 

```{r}
library(brms)
library(tidyverse)
dat<-read.csv('vsres.csv', check.names=FALSE)
```


```{r}
longdat<-dat %>% pivot_longer(!ID, names_to = c("dif","ss"), values_to = "RT", names_sep = ' ')
ggplot(data=longdat, mapping=aes(x=ss,y=RT,color=dif))+geom_violin()

brmvs<-brm(
  RT ~ ss + dif + ss:dif,
  family = shifted_lognormal(),
  data = longdat,
  prior=NULL
)
brmvs
eff<-conditional_effects(brmvs, effects='ss:dif')
plot(eff,points=TRUE)
```

